# CHAPTER 16 Keypoints and Descriptors

## Introduction Optical Flow

**Q**：什么是光流？

**A**：通俗来讲，把图像中的每一个点的瞬时速度和方向找出来就是光流。  

**Q**：光流跟踪主要是解决什么问题？

**A**：光流问题涉及到试图找出一幅图像中的许多点(可能是所有点)在另一幅图像中移动到哪里-通常这是在视频序列中完成的。 可以合理地假设，第一帧中的大部分点都可以在第二帧的某个地方找到。  

**Q**：光流有哪些应用场景？
**A**：光学流可以用于场景中的对象的运动估计，或者甚至用于相机相对于场景整体的自我运动。

**Q**：光流算法有哪些分类？
**A**：根据是否对所有点进行跟踪，将光流算法分为**稠密光流（dense optical flow）**和**稀疏光流（sparse optical flow）**。稠密光流对图像中每个像素进行跟踪，稀疏光流对指定点进行跟踪。稀疏光流相比较于稠密光流的优化在计算开销小，算法更加快速和可靠。  

## Lucas-Kanade Method for Sparse Optical Flow

**问**：LK光流可以用于稀疏光流的原因是什么？
**答**：该算法可以应用于稀疏上下文中，因为它只依赖于从每个感兴趣点周围的某个小窗口派生出来的局部信息。

**问**：如何评价LK光流算法？
**答**：LK光流算法首先设置一下领域的窗口，之后计算光流，当窗口较大时，光流计算更健壮，当窗口较小时，光流计算更正确。

**问**：如何解决LK光流算法健壮性和正确性之间矛盾的问题？
**答**：这个问题导致了“金字塔”LK算法的发展，该算法从图像金字塔的最高层(最低细节)开始跟踪，向下工作到更低层次(更精细的细节)。采用金字塔的方法，即窗口固定，将图像生成金字塔，在每一层金字塔上都用同一个大小的窗口来进行光流计算。图像小，窗口显大，计算鲁棒性好，图像大，窗口显小，计算更正确。这是一个由粗到精的过程。

## How Lucas-Kanade works

**问**：LK算法的基本思想基于哪些假设？
**答**：  
1）**亮度恒定性（Brightness constancy）**；  
2）**时间连续或“小移动”（Temporal persistence, or "small movements"）**：图像运动的表面块（surface patch）在时间上变化缓慢。在实践中，这意味着相对于图像中的运动尺度而言，时间增量是足够快的，而对象在一帧到另一个帧不会移动太快。  
3）**空间相干性（Spatial coherence）**：场景中的相邻点属于同一表面，具有相似的运动，并投射到图像平面上的附近点。  


第一个要求，亮度恒定，只是要求一个跟踪块中的像素随着时间的推移看起来是相同的，定义如下：

$$ f(x,t) \equiv I(x(t),t)=I(x(t+dt),t+dt) \tag{1}$$

![1](./Figure16-4.png)

我们跟踪的像素强度不随时间变化的要求可以简单地表示为：

$$\frac{\partial f(x)}{\partial t}=0 \tag{2}
$$


在这种情况下，我们可以从亮度一致性方程（2）开始，在考虑$x$依赖于$t$，用$I(x(t)，t)$代替亮度$f(x，t)$。 应用链规则进行局部微分。这就产生了：  
![1](./4.png)  
其中，$I_{x}$是图像的偏导数，$I_{t}$是图像随时间的导数，$v$是要求解的速度。因此，在简单的一维情况下，我们得到了光流速度的简单方程：

$$-\frac{I_{t}}{I_{x}}=v \tag{3}$$

我们的目标是识别边缘移动的速度v，如图16-5所示。
![1](./5.png) 

**问**：既然可以用公式（3）求解光流速度，为什么还要用迭代法求解速度？
<br>**答**：由于图像的亮度实际上不是恒定的，时间步长（由摄像机决定）也不是如我们期望的相对于运动足够短，所以我们求解的速度并不准确。但是，如果求解到的速度与实际的速度“足够接近”，就可以用迭代的方法来解决这个问题，如图所示，将第一次估计的速度（不准确的）作为初始值进行下一次迭代并重复这个过程。根据沿$x$运动的像素不变的亮度恒定假设，在迭代过程中，可以保持使用由第一帧计算得到的$x$的空间导数。这种重复使用已经计算出的空间导数极大地节省了计算开销。时间导数仍需要在每次迭代和每一帧中重复计算，但如果初始值与实际值足够接近，迭代过程在5次迭代之内就会收敛到接近的准确值，这就是所谓的牛顿法。如果初始估计值与实际值相差比较大，则牛顿法实际上是发散的。

![1](./6.png) 













我们选择的点或特征应该是唯一的，或者几乎是唯一的，并且应该是可参数化的，以便可以与其他图像中的其他点进行比较(见图16-1)。

如果在两个不同的方向附近观察到强导数，那么我们可以希望这一点更有可能是唯一的。

Finding corners using cv::goodFeaturesToTrack()

cv：GoodFeaturesToTrack()例程实现了Harris的方法，并对ShiI和Tomasi[Shi94]作了轻微的改进。这个函数可以方便地计算必要的导数操作符， 分析它们，并返回符合我们定义的适合跟踪的点的列表。

![1](./goodFeaturesToTrack.png)

参数说明：

输入**image**可以为任意的8位或32位（例如，8U或32F），单通道图片。
输出**corners**（类型可以为vector型也可以为array型，这由你提供的决定）包括所有发现的角点（corner）。如果是vector<>，应为cv::Point2f型的对象。

####  Pyramid Lucas-Kanade code: cv::calcOpticalFlowPyrLK()

![2](./calcOpticalFlowPyrLK.png)

**prevImg**和**nextImg**为前后两帧图片，它们必须要有相同的大小以及相同的通道数。<br>**prevPts**为前一帧的特征点作为输入，**nextPts**为由前一帧的特征点根据特征点跟踪找出后一帧上的特征点作为输出。<br> 特别的，**status**中的每一项都将说明是否找到了**prePts**中的相应特征(status[i]将是非零的当且仅当prePts[i]在nextImg中找到)。<br>**err[i]** 与**status[i]** 相反。<br>**winSize**表示窗口大小，在计算局部相干运动（local coherent motion）用到该窗口。<br>**maxLevel**用于设置图像的深度即金字塔层数，如果**maxLevel**设置成0，则不使用金字塔。<br>参数**criteria**、**flags**和minEigThreshold目前无需设置，先不管。

### 参考书籍

OReilly.Learning.OpenCV.3.2016.12.pdf

# 